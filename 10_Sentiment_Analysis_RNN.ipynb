{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/binhvd/Data-Analytics-3-Labs/blob/main/10_Sentiment_Analysis_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBegnwVciX3q"
      },
      "source": [
        "## Setup the Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUDYEREAydsp"
      },
      "source": [
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Dense, SimpleRNN, Activation, Dropout, Conv1D\n",
        "from tensorflow.keras.layers import Embedding, Flatten, LSTM, GRU\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2GGZkNBiUDO"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/haochen23/nlp-rnn-lstm-sentiment/master/training.1600000.processed.noemoticon.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm3EV9KeoKX5",
        "outputId": "738a36cd-9fd0-4248-c028-82511fc1105b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-18 07:38:13--  https://raw.githubusercontent.com/haochen23/nlp-rnn-lstm-sentiment/master/training.1600000.processed.noemoticon.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2989873 (2.9M) [text/plain]\n",
            "Saving to: ‘training.1600000.processed.noemoticon.csv’\n",
            "\n",
            "training.1600000.pr 100%[===================>]   2.85M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-10-18 07:38:14 (248 MB/s) - ‘training.1600000.processed.noemoticon.csv’ saved [2989873/2989873]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFAlVSfR-LOf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "207c8984-408d-4f29-f9f0-54465b9968d8"
      },
      "source": [
        "data = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", header=None, encoding='latin-1')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0           1                             2         3                4  \\\n",
              "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
              "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
              "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
              "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
              "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
              "\n",
              "                                                   5  \n",
              "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1  is upset that he can't update his Facebook by ...  \n",
              "2  @Kenichan I dived many times for the ball. Man...  \n",
              "3    my whole body feels itchy and like its on fire   \n",
              "4  @nationwideclass no, it's not behaving at all....  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45cf6b4a-7eaf-4368-b8d3-7b3c087274fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45cf6b4a-7eaf-4368-b8d3-7b3c087274fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45cf6b4a-7eaf-4368-b8d3-7b3c087274fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45cf6b4a-7eaf-4368-b8d3-7b3c087274fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB_zc38FjQjE",
        "outputId": "07f757c4-de39-4bab-c91f-7d861079e586"
      },
      "source": [
        "# Check for missing values\n",
        "data.isnull().any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    False\n",
              "1    False\n",
              "2    False\n",
              "3    False\n",
              "4    False\n",
              "5    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBS6ajOHkBBf"
      },
      "source": [
        "## Preparing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_8gm-fukIQj"
      },
      "source": [
        "We only care about the tweet text and tweet sentiment information, which stored in the 5th column and 0th column in the dataset. In the sentiment column, 0 represents negative, and 1 represents positive.\n",
        "\n",
        "We organize the data as data_X contains all the tweet text, data_y contains the labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaPV8cXIkyjR"
      },
      "source": [
        "The following code will convert the tweet text data_X to sequence format that will be feed into RNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVX5M3jV_WOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "255ca751-fa5f-4eef-bef4-b047c9d4729c"
      },
      "source": [
        "data_X = data[5]\n",
        "print(data_X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
            "1        is upset that he can't update his Facebook by ...\n",
            "2        @Kenichan I dived many times for the ball. Man...\n",
            "3          my whole body feels itchy and like its on fire \n",
            "4        @nationwideclass no, it's not behaving at all....\n",
            "                               ...                        \n",
            "19995    Just woke up. Having no school is the best fee...\n",
            "19996    TheWDB.com - Very cool to hear old Walt interv...\n",
            "19997    Are you ready for your MoJo Makeover? Ask me f...\n",
            "19998    Happy 38th Birthday to my boo of alll time!!! ...\n",
            "19999    happy #charitytuesday @theNSPCC @SparksCharity...\n",
            "Name: 5, Length: 20000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Label:\n",
        "*   0 -> NEGATIVE\n",
        "*   2 -> NEUTRAL\n",
        "*   4 -> POSITIVE"
      ],
      "metadata": {
        "id": "RINdPERcXARu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt_DCR2SGvGR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "382566ae-cac6-431b-8db5-27bf31ffd5ee"
      },
      "source": [
        "data_y = pd.get_dummies(data[0]).to_numpy()\n",
        "print(data_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odrbjT-ClZEn"
      },
      "source": [
        "Splitting Data for Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBWMDqltvnHK"
      },
      "source": [
        "# TODO: Split data into train and valid sets\n",
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "X3KasVGeR7-Z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMpyUa8Dt8zH"
      },
      "source": [
        "MAX_VOCAB = 18000\n",
        "MAX_LEN = 150\n",
        "EMBED_SIZE = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Tokenize inputs\n",
        "..."
      ],
      "metadata": {
        "id": "JXaHmlwpCMbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Text padding\n",
        "..."
      ],
      "metadata": {
        "id": "hopnUDHbCYbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC90NhQYRzhQ",
        "outputId": "4c2161c4-bbfc-4fab-e7f6-bb61129a7742"
      },
      "source": [
        "train_X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  50, 3733,   37, ..., 2638,    1,  308],\n",
              "       [ 178, 7110, 2291, ...,  711,  110,   39],\n",
              "       [ 120,  105,  316, ...,  629,  105,   86],\n",
              "       ...,\n",
              "       [   8,  933,  118, ..., 1088,  383,    7],\n",
              "       [ 118,   10,   34, ...,    0,    0,    0],\n",
              "       [   9,    1,  750, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gd1NpvNlfjI"
      },
      "source": [
        "## Preparing Word Embeddings using the GloVe Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpIBFSi8oVyW",
        "outputId": "b8766399-ab7f-4c89-d641-f4594e19d2e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkOVxFEzkx-v",
        "outputId": "5b6986a3-e967-47bc-c3c0-e0e992265d25"
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load the twitter embeddings model. This model is trained on 2 billion tweets, which contains 27 billion tokens, 1.2 million vocabs.\n",
        "# might take a while\n",
        "glove_model = api.load(\"glove-twitter-200\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 758.5/758.5MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6didFc14I-9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d85609c-5ad9-4989-b830-4a74c066956a"
      },
      "source": [
        "# calcultaete number of words\n",
        "nb_words = len(word_index) + 1\n",
        "print('All words: ', nb_words)\n",
        "\n",
        "# obtain the word embedding matrix\n",
        "embedding_matrix = np.zeros((nb_words, EMBED_SIZE))\n",
        "for word, i in word_index.items():\n",
        "    if word in glove_model:\n",
        "        embedding_matrix[i] = glove_model[word]\n",
        "\n",
        "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null word embeddings: 4103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7obYrO0MZTHN"
      },
      "source": [
        "**Explanation of the steps performed till now**\n",
        "\n",
        "Tweets: Is upset that he can't update his Facebook..\n",
        "\n",
        "Expected Input to RNN model - \n",
        "Is - Embeddings [200] (32)\n",
        "\n",
        "upset - Embeddings [200] (450)\n",
        "\n",
        "that - Embeddings [200] (43)\n",
        "\n",
        "he - Embeddings [200] (56)\n",
        "\n",
        "1. Vocabulary of all tweets: 30257 unique tokens\n",
        "2. Unique token IDs: ID (1, 2, 3, 4... for all the 30257 tokens)\n",
        "3. Tweets represented as the sequence of IDs [32 450 43 56 ...]\n",
        "\n",
        "Padding: \n",
        "\"Commonly in RNN's, we take the final output or hidden state and use this to make a prediction (or do whatever task we are trying to do).\n",
        "If we send a bunch of 0's to the RNN before taking the final output (i.e. 'post' padding as you describe), then the hidden state of the network at the final word in the sentence would likely get 'flushed out' to some extent by all the zero inputs that come after this word.\n",
        "So intuitively, this might be why pre-padding is more popular/effective.\" - [link](https://stackoverflow.com/questions/46298793/how-does-choosing-between-pre-and-post-zero-padding-of-sequences-impact-results)\n",
        "\n",
        "Padding for RNNs - [Link](https://datascience.stackexchange.com/questions/49168/padding-sequences-for-neural-sequence-models-rnns)\n",
        "\n",
        "[Paper](https://arxiv.org/abs/1903.07288)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A9N9LKhlwS_"
      },
      "source": [
        "## Training and Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEjtnTkLl1dG"
      },
      "source": [
        "Train and evaluate the SimpleRNN, LSTM, and GRU networks on our prepared dataset.\n",
        "\n",
        "We are using the pre-trained word embeddings from the glove.twitter.27B.200d.txt data. Using the pre-trained word embeddings as weights for the Embedding layer leads to better results and faster convergence.\n",
        "\n",
        "We set each models to run 20 epochs, but we also set EarlyStopping rules to prevent overfitting. The results of the SimpleRNN, LSTM, GRU models can be seen below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QoxYEfl6zr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bac74b11-2e91-4c0f-bbfa-40702cbe4504"
      },
      "source": [
        "model_rnn = Sequential()\n",
        "model_rnn.add(Embedding(nb_words, EMBED_SIZE, weights=[embedding_matrix], input_length=MAX_LEN, trainable = False))\n",
        "\n",
        "# TODO: Add a SimpleRNN layer\n",
        "...\n",
        "\n",
        "model_rnn.add(Dense(2, activation='softmax'))\n",
        "model_rnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model_rnn.fit(train_X, train_y, epochs=20, batch_size=120,\n",
        "          validation_data=(valid_X, valid_y), callbacks=EarlyStopping(monitor='val_accuracy', mode='max',patience=3))\n",
        "\n",
        "predictions = model_rnn.predict(valid_X)\n",
        "predictions = predictions.argmax(axis=1)\n",
        "print(classification_report(valid_y.argmax(axis=1), predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "134/134 [==============================] - 4s 23ms/step - loss: 0.6031 - accuracy: 0.6779 - val_loss: 0.5610 - val_accuracy: 0.7125\n",
            "Epoch 2/20\n",
            "134/134 [==============================] - 3s 20ms/step - loss: 0.5531 - accuracy: 0.7225 - val_loss: 0.5515 - val_accuracy: 0.7237\n",
            "Epoch 3/20\n",
            "134/134 [==============================] - 3s 20ms/step - loss: 0.5360 - accuracy: 0.7319 - val_loss: 0.5487 - val_accuracy: 0.7215\n",
            "Epoch 4/20\n",
            "134/134 [==============================] - 3s 20ms/step - loss: 0.5275 - accuracy: 0.7381 - val_loss: 0.5512 - val_accuracy: 0.7185\n",
            "Epoch 5/20\n",
            "134/134 [==============================] - 3s 20ms/step - loss: 0.5128 - accuracy: 0.7495 - val_loss: 0.5747 - val_accuracy: 0.7153\n",
            "125/125 [==============================] - 1s 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.70      0.71      2018\n",
            "           1       0.71      0.73      0.72      1982\n",
            "\n",
            "    accuracy                           0.72      4000\n",
            "   macro avg       0.72      0.72      0.72      4000\n",
            "weighted avg       0.72      0.72      0.72      4000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlA_9skrnjNk"
      },
      "source": [
        "## LSTM and GRUs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Train a LSTM model by replacing the SimpleRNN layer with a LSTM layer\n",
        "model_lstm = ...\n",
        "\n",
        "# TODO: Print a classification report for the model\n",
        "..."
      ],
      "metadata": {
        "id": "OKvNzMFLDTKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Train a GRU model by replacing the SimpleRNN layer with a GRU layer\n",
        "model_gru = ...\n",
        "\n",
        "\n",
        "# TODO: Print a classification report for the model\n",
        "..."
      ],
      "metadata": {
        "id": "pFGOeicaDdIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "8WxX4omTU47e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def predict(model, text):\n",
        "    start_at = time.time()\n",
        "    # Tokenize text\n",
        "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=MAX_LEN)\n",
        "    # Predict\n",
        "    score = model.predict([x_test])[0]\n",
        "\n",
        "    return {\"NEGATIVE\": score[0], \"POSITIVE\": score[1],\n",
        "       \"elapsed_time\": time.time()-start_at}  "
      ],
      "metadata": {
        "id": "US8I2F97VM6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Try few sentences to check the models\n",
        "predict(model_lstm, \"I feel not so good today\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2bcdf7c-5f13-4601-fb96-abf045ecc726",
        "id": "nanHEo8HWZgM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'NEGATIVE': 0.60516524,\n",
              " 'POSITIVE': 0.39483473,\n",
              " 'elapsed_time': 0.09723186492919922}"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-trained Word Embeddings\n",
        "\n",
        "Try training the RNNs with word embeddings but without the pre-trained weight and compare the results with the pre-trained model.\n"
      ],
      "metadata": {
        "id": "S93_jWlCBFEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Remove embedding_matrix and set trainable=TRUE\n",
        "..."
      ],
      "metadata": {
        "id": "thNscra7DoZC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}